{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xtractopy - multitrack function (name pending)\n",
    "\n",
    "*Andrew Chin, 11/19/21*\n",
    "\n",
    "Draft of running multiple satellite tags at a time and running the matching function at the same time. Running the base function multiple times may be ok with 1-20 animals, but if you have a lot to run, it would be more time efficient to combine all the satellite data together into one `pandas` df and running the `xtractopy` function on it. \n",
    "\n",
    "This function will take the following inputs:\n",
    "\n",
    "1. multiple `pandas` dfs as objects\n",
    "\n",
    "and output:\n",
    "1. a combined df with a new column, \"tag_ID\", that is associated with its original df\n",
    "\n",
    "this function could be an entirely new function that performs the basic transformation that `xtractopy` does, or it could stand alone as a datacleaning function. Depends on utility of the function for other purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized function `xtractopy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Union\n",
    "import fsspec\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "Below is an example of an `xtractopy` workflow from OHW 2021. We will be working with tiger sharks (*Galeocerdo cuvier*) tagged in the Gulf Stream system of the Western Atlantic Ocean.\n",
    "\n",
    "![tigershark](tigershark_lauramcdonnell.png)\n",
    "\n",
    "First, let's load in the track data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shark_dir = \"track_shark144020.csv\"\n",
    "track_ex = pd.read_csv(shark_dir, parse_dates=['datetime']) # in pandas, read_csv\n",
    "\n",
    "# track_ex[\"lon\"] = np.where(\n",
    "#     track_ex[\"lon\"] < 180,\n",
    "#     track_ex[\"lon\"] + 360,\n",
    "#     track_ex[\"lon\"])\n",
    "\n",
    "lat_min = track_ex[\"lat\"].min() - 2.0\n",
    "lat_max = track_ex[\"lat\"].max() + 2.0\n",
    "lon_min = track_ex[\"lon\"].min() - 2.0\n",
    "lon_max = track_ex[\"lon\"].max() + 2.0\n",
    "\n",
    "xy_bbox = dict(latitude=slice(lat_min,lat_max), longitude=slice(lon_min,lon_max))\n",
    "\n",
    "plt.plot(track_ex.lon,track_ex.lat)\n",
    "\n",
    "xy_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "track_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grab track data for a few tag datapoints\n",
    "track_2014 = track_ex.iloc[0:100]\n",
    "track_2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in environmental data\n",
    "We want to retrieve high resolution data from web repositories and servers and load them into the Python environment as an xarray. In addition, we recommend subsetting the data to the particular study grid for faster run-times. We have a built-in function, `subset_area`, that only requires three simple inputs.\n",
    "\n",
    "here is the SST from MUR, available [here](https://registry.opendata.aws/mur/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bring in data for SST\n",
    "file_location = 's3://mur-sst/zarr'\n",
    "ikey = fsspec.get_mapper(file_location, anon=True)\n",
    "ds_sst = xr.open_zarr(ikey,consolidated=True)\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the longitudinal extent of your study area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of Gulf Stream \n",
    "max_lon_glf = -70\n",
    "min_lon_glf = -82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generalized data subset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_area(env_data,\n",
    "                max_lon,\n",
    "                min_lon):\n",
    "    subset_lon = (env_data.lon >= min_lon) & (env_data.lon <= max_lon)\n",
    "    subset_env_data = env_data.where(subset_lon, drop=True)\n",
    "    return subset_env_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gulf_stream_sst = subset_area(ds_sst, max_lon_glf, min_lon_glf)\n",
    "gulf_stream_sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def xtractopy(envdata,\n",
    "              tagdata: pd.DataFrame,\n",
    "             filename: [str]):\n",
    "    \"\"\"\n",
    "    envdata: environmental data in an DataArray format\n",
    "    tagdata: tag data in a pandas format\n",
    "    filename: the name of the file .csv output file, as a \"string\"\n",
    "    \"\"\"\n",
    "    def fuction_dataset_point(**kwargs) -> Dict[str, Union[float, int]]:\n",
    "        pass\n",
    "\n",
    "    def extract(function_dataset_point, \n",
    "                df: tagdata, \n",
    "                map_coordinates: Dict[str, str], \n",
    "                rename_variables: Dict[str, str]\n",
    "               ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        function_dataset_point: environmental data in a point format, to be transformed\n",
    "        map_coordinates: key is name of column in dataframe, value is the name of the coordinate in dataset\n",
    "        rename_variables: TBD\n",
    "        \"\"\"\n",
    "    \n",
    "        def get_row(row) -> Dict[str, Union[float, int]]:\n",
    "            extract_coordinates = {}\n",
    "        \n",
    "            for key, val in map_coordinates.items():\n",
    "                extract_coordinates[val] = row[key]\n",
    "        \n",
    "            result = function_dataset_point(**extract_coordinates)\n",
    "        \n",
    "            # rename variables here and transform result TBD\n",
    "            return result\n",
    "    \n",
    "        return df.apply(\n",
    "            lambda row: get_row(row), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def envdata_point(lat, lon, time) -> Dict[str, Union[float, int]]:\n",
    "        ds = envdata.sel(lat=lat, lon=lon, time=time, method=\"nearest\")\n",
    "\n",
    "        results = {}\n",
    "    \n",
    "        for var in ds.variables:\n",
    "            if var not in ds.coords:\n",
    "                results[var] = ds[var].values\n",
    "    \n",
    "        return results\n",
    "\n",
    "    combined_dat = pd.concat([tagdata, \n",
    "                        extract(envdata_point,\n",
    "                                tagdata, \n",
    "                                {\"lat\": \"lat\", \"lon\": \"lon\", \"datetime\": \"time\"}, \n",
    "                                {}\n",
    "                               )\n",
    "                       ], axis=1)\n",
    "    combined_dat.to_csv(\"\".join([filename, \".csv\"])) # need to figure out how to paste the title into the csv file\n",
    "    return combined_dat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST THE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test\n",
    "xtractopy(ds_sst, track_2014, \"test_sst\")\n",
    "xtractopy(ds_ssh_renamed, track_2014, \"test_ssh\")\n",
    "xtractopy(ds_chl_renamed, track_2014, \"test_chla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract two environmental variables with `xtractopy2` function\n",
    "This function is the same as `xtractopy` but accepts two environmental data xArrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xtractopy2(envdata1,\n",
    "              envdata2,\n",
    "              tagdata: pd.DataFrame,\n",
    "             filename: [str]):\n",
    "    \"\"\"\n",
    "    envdata: environmental data in an DataArray format\n",
    "    tagdata: tag data in a pandas format\n",
    "    filename: the name of the file .csv output file, as a \"string\"\n",
    "    \"\"\"\n",
    "    def fuction_dataset_point(**kwargs) -> Dict[str, Union[float, int]]:\n",
    "        pass\n",
    "\n",
    "    def extract(function_dataset_point, \n",
    "                df: tagdata, \n",
    "                map_coordinates: Dict[str, str], \n",
    "                rename_variables: Dict[str, str]\n",
    "               ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        function_dataset_point: environmental data in a point format, to be transformed\n",
    "        map_coordinates: key is name of column in dataframe, value is the name of the coordinate in dataset\n",
    "        rename_variables: TBD\n",
    "        \"\"\"\n",
    "    \n",
    "        def get_row(row) -> Dict[str, Union[float, int]]:\n",
    "            extract_coordinates = {}\n",
    "        \n",
    "            for key, val in map_coordinates.items():\n",
    "                extract_coordinates[val] = row[key]\n",
    "        \n",
    "            result = function_dataset_point(**extract_coordinates)\n",
    "        \n",
    "            # rename variables here and transform result TBD\n",
    "            return result\n",
    "    \n",
    "        return df.apply(\n",
    "            lambda row: get_row(row), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def envdata1_point(lat, lon, time) -> Dict[str, Union[float, int]]:\n",
    "        ds = envdata1.sel(lat=lat, lon=lon, time=time, method=\"nearest\")\n",
    "\n",
    "        results = {}\n",
    "    \n",
    "        for var in ds.variables:\n",
    "            if var not in ds.coords:\n",
    "                results[var] = ds[var].values\n",
    "        return results\n",
    "    \n",
    "    def envdata2_point(lat, lon, time) -> Dict[str, Union[float, int]]:\n",
    "        ds = envdata2.sel(lat=lat, lon=lon, time=time, method=\"nearest\")\n",
    "\n",
    "        results = {}\n",
    "    \n",
    "        for var in ds.variables:\n",
    "            if var not in ds.coords:\n",
    "                results[var] = ds[var].values\n",
    "        return results\n",
    "\n",
    "    combined2_dat = pd.concat([tagdata, \n",
    "                        extract(envdata1_point,\n",
    "                                tagdata, \n",
    "                                {\"lat\": \"lat\", \"lon\": \"lon\", \"datetime\": \"time\"}, \n",
    "                                {}\n",
    "                               ),\n",
    "                        extract(envdata2_point,\n",
    "                                tagdata, \n",
    "                                {\"lat\": \"lat\", \"lon\": \"lon\", \"datetime\": \"time\"}, \n",
    "                                {}\n",
    "                               )\n",
    "                       ], axis=1)\n",
    "    combined2_dat.to_csv(\"\".join([filename, \".csv\"])) # need to figure out how to paste the title into the csv file\n",
    "    return combined2_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtractopy2(ds_sst, ds_ssh_renamed, track_2014, \"test_sst_ssh\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
